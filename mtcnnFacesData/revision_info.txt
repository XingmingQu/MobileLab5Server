arguments: src/align/align_dataset_mtcnn.py ./imageData ./mtcnnFacesData --image_size 160 --margin 32 --random_order
--------------------
tensorflow version: 1.15.0
--------------------
git hash: b'5f8cfdb724f42eb90292da038f088d669a60f6d7'
--------------------
b'diff --git a/sklearnhandlers.py b/sklearnhandlers.py\nindex afea865..a845e45 100644\n--- a/sklearnhandlers.py\n+++ b/sklearnhandlers.py\n@@ -9,7 +9,7 @@ from tornado.ioloop import IOLoop\n from tornado.options import define, options\n \n from basehandler import BaseHandler\n-\n+import subprocess as sp\n from sklearn.neighbors import KNeighborsClassifier\n import pickle\n from bson.binary import Binary\n@@ -97,49 +97,109 @@ class UpdateModelForDatasetId(BaseHandler):\n         \'\'\'\n         dsid = self.get_int_arg("dsid",default=0)\n \n-        # create feature vectors from database\n-        f=[];\n-        for a in self.db.labeledinstances.find({"dsid":dsid}): \n-            f.append([float(val) for val in a[\'feature\']])\n-\n-        # create label vector from database\n-        l=[];\n-        for a in self.db.labeledinstances.find({"dsid":dsid}): \n-            l.append(a[\'label\'])\n-\n-        # fit the model to the data\n-        c1 = KNeighborsClassifier(n_neighbors=1);\n-        acc = -1;\n-        if l:\n-            c1.fit(f,l) # training\n-            lstar = c1.predict(f)\n-            self.clf = c1\n-            acc = sum(lstar==l)/float(len(l))\n-            bytes = pickle.dumps(c1)\n+        # # create feature vectors from database\n+        # f=[];\n+        # for a in self.db.labeledinstances.find({"dsid":dsid}): \n+        #     f.append([float(val) for val in a[\'feature\']])\n+\n+        # # create label vector from database\n+        # l=[];\n+        # for a in self.db.labeledinstances.find({"dsid":dsid}): \n+        #     l.append(a[\'label\'])\n+\n+        # # fit the model to the data\n+        # c1 = KNeighborsClassifier(n_neighbors=1);\n+\n+        data_folder = \'./mtcnnFacesData\'\n+        face_net_model = \'/Users/xqu/datasets/pretrain/20180402-114759.pb\'\n+        output_model = \'./model/mySVMmodel.pkl\'\n+        batch_size = 10\n+        augment_times = 20\n+\n+        face_detection_corp_face ="""python src/align/align_dataset_mtcnn.py \\\n+                                ./imageData \\\n+                                ./mtcnnFacesData \\\n+                                --image_size 160 \\\n+                                --margin 32 \\\n+                                --random_order\n+        """\n+\n+        print("Now croping face from image........\\n\\n")\n+        flag=sp.call(face_detection_corp_face,shell=True)\n+        if flag!=0:\n+            raise Exception(\'Please check python src/align/align_dataset_mtcnn.py  cmd \')\n+        else:\n+            print(\'\\nFinished\')\n+\n+        cmd = """python myclassifier.py TRAIN \\\n+        {} \\\n+        {} \\\n+        {} \\\n+        --batch_size {} \\\n+        --augment_times {}""".format(data_folder,face_net_model,output_model,batch_size,augment_times)\n+\n+        print("Now runing myclassifer........")\n+        flag=sp.call(cmd,shell=True)\n+        if flag!=0:\n+            raise Exception(\'Please check python myclassifier.py cmd \')\n+        else:\n+            print(\'\\nFinished\')\n+\n+        with open(output_model, \'rb\') as infile:\n+            (model, class_names) = pickle.load(infile)\n+\n+\n+            self.clf = model\n+            bytes = pickle.dumps(self.clf)\n             self.db.models.update({"dsid":dsid},\n                 {  "$set": {"model":Binary(bytes)}  },\n                 upsert=True)\n \n-        # send back the resubstitution accuracy\n-        # if training takes a while, we are blocking tornado!! No!!\n-        self.write_json({"resubAccuracy":acc})\n+            # send back the resubstitution accuracy\n+            # if training takes a while, we are blocking tornado!! No!!\n+            self.write_json({"log":"Finished model training"})\n \n class PredictOneFromDatasetId(BaseHandler):\n     def post(self):\n         \'\'\'Predict the class of a sent feature vector\n         \'\'\'\n-        data = json.loads(self.request.body.decode("utf-8"))    \n-\n-        vals = data[\'feature\'];\n-        fvals = [float(val) for val in vals];\n-        fvals = np.array(fvals).reshape(1, -1)\n-        dsid  = data[\'dsid\']\n-\n-        # load the model from the database (using pickle)\n-        # we are blocking tornado!! no!!\n-        if(self.clf == []):\n-            print(\'Loading Model From DB\')\n-            tmp = self.db.models.find_one({"dsid":dsid})\n-            self.clf = pickle.loads(tmp[\'model\'])\n-        predLabel = self.clf.predict(fvals);\n-        self.write_json({"prediction":str(predLabel)})\n+        # data = json.loads(self.request.body.decode("utf-8"))    \n+\n+        # vals = data[\'feature\'];\n+        # fvals = [float(val) for val in vals];\n+        # fvals = np.array(fvals).reshape(1, -1)\n+        # dsid  = data[\'dsid\']\n+\n+        # # load the model from the database (using pickle)\n+        # # we are blocking tornado!! no!!\n+        # if(self.clf == []):\n+        #     print(\'Loading Model From DB\')\n+        #     tmp = self.db.models.find_one({"dsid":dsid})\n+        #     self.clf = pickle.loads(tmp[\'model\'])\n+        # predLabel = self.clf.predict(fvals);\n+        # self.write_json({"prediction":str(predLabel)})\n+        data = json.loads(self.request.body.decode("utf-8"))\n+\n+        vals = data[\'feature\']\n+        image = stringToRGB(vals)\n+        # vals = image\n+        print(\'\\n\\n\\n\\n\',image.shape)\n+        # fvals = [float(val) for val in vals]\n+        label = data[\'label\']\n+        sess  = data[\'dsid\']\n+\n+        face = self.faceEmbedding(image)\n+\n+        print(\'\\n\\n\\n\',face.shape)\n+        predictions = self.clf.predict_proba(emb_array)\n+        best_class_indices = np.argmax(predictions, axis=1)\n+        best_class_probabilities = predictions[np.arange(len(best_class_indices)), best_class_indices]\n+        if best_class_probabilities[0] > 0.3:\n+            pre=float(best_class_probabilities[i])*100\n+            pre= round(pre,2)\n+            pre=str(pre)+\'%\'\n+            a=class_names[best_class_indices[i]].split(\' \')\n+            result=a[0]\n+            self.write_json({"prediction":str(result+\' \'+pre)})\n+        else:\n+            self.write_json({"prediction":str("UNKNOWN")})\ndiff --git a/tornado_scikit_learn.py b/tornado_scikit_learn.py\nindex c32b2db..50f717b 100644\n--- a/tornado_scikit_learn.py\n+++ b/tornado_scikit_learn.py\n@@ -79,7 +79,7 @@ class Application(tornado.web.Application):\n         self.handlers_string = str(handlers)\n \n         try:\n-            self.client  = MongoClient(serverSelectionTimeoutMS=50) # local host, default port\n+            self.client  = MongoClient(serverSelectionTimeoutMS=999999) # local host, default port\n             print(self.client.server_info()) # force pymongo to look for possible running servers, error if none running\n             # if we get here, at least one instance of pymongo is running\n             self.db = self.client.sklearndatabase # database with labeledinstances, models'